{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nA scandal in Bohemia 01,\\nThe Red-Headed League,2\\nA Case, of Identity 33\\nThe Boscombe Valley Mystery4\\nThe Five Orange Pips1\\nThe Man with? the Twisted Lip\\nThe Adventure of the Blue Carbuncle\\nThe Adventure of the Speckled Band\\nThe Adventure of the Engineer's Thumb\\nThe Adventure of the Noble Bachelor\\nThe Adventure of the Beryl Coronet\\nThe Adventure of the Copper Beeches\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "text = \"\"\"\n",
    "A scandal in Bohemia 01,\n",
    "The Red-Headed League,2\n",
    "A Case, of Identity 33\n",
    "The Boscombe Valley Mystery4\n",
    "The Five Orange Pips1\n",
    "The Man with? the Twisted Lip\n",
    "The Adventure of the Blue Carbuncle\n",
    "The Adventure of the Speckled Band\n",
    "The Adventure of the Engineer's Thumb\n",
    "The Adventure of the Noble Bachelor\n",
    "The Adventure of the Beryl Coronet\n",
    "The Adventure of the Copper Beeches\n",
    "\"\"\"\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'A scandal in Bohemia 01,',\n",
       " 'The Red-Headed League,2',\n",
       " 'A Case, of Identity 33',\n",
       " 'The Boscombe Valley Mystery4',\n",
       " 'The Five Orange Pips1',\n",
       " 'The Man with? the Twisted Lip',\n",
       " 'The Adventure of the Blue Carbuncle',\n",
       " 'The Adventure of the Speckled Band',\n",
       " \"The Adventure of the Engineer's Thumb\",\n",
       " 'The Adventure of the Noble Bachelor',\n",
       " 'The Adventure of the Beryl Coronet',\n",
       " 'The Adventure of the Copper Beeches',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_array = text.split(\"\\n\")\n",
    "text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          \n",
       "1                  A scandal in Bohemia 01,\n",
       "2                   The Red-Headed League,2\n",
       "3                    A Case, of Identity 33\n",
       "4              The Boscombe Valley Mystery4\n",
       "5                     The Five Orange Pips1\n",
       "6             The Man with? the Twisted Lip\n",
       "7       The Adventure of the Blue Carbuncle\n",
       "8        The Adventure of the Speckled Band\n",
       "9     The Adventure of the Engineer's Thumb\n",
       "10      The Adventure of the Noble Bachelor\n",
       "11       The Adventure of the Beryl Coronet\n",
       "12      The Adventure of the Copper Beeches\n",
       "13                                         \n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vector = pd.Series(text_array)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vector[1:len(vector)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A scandal in Bohemia 01,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Red-Headed League,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Case, of Identity 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Boscombe Valley Mystery4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Five Orange Pips1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Man with? the Twisted Lip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Adventure of the Blue Carbuncle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Adventure of the Speckled Band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Adventure of the Engineer's Thumb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Adventure of the Noble Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Adventure of the Beryl Coronet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Adventure of the Copper Beeches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Texts\n",
       "1                A scandal in Bohemia 01,\n",
       "2                 The Red-Headed League,2\n",
       "3                  A Case, of Identity 33\n",
       "4            The Boscombe Valley Mystery4\n",
       "5                   The Five Orange Pips1\n",
       "6           The Man with? the Twisted Lip\n",
       "7     The Adventure of the Blue Carbuncle\n",
       "8      The Adventure of the Speckled Band\n",
       "9   The Adventure of the Engineer's Thumb\n",
       "10    The Adventure of the Noble Bachelor\n",
       "11     The Adventure of the Beryl Coronet\n",
       "12    The Adventure of the Copper Beeches"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df = pd.DataFrame(vector, columns=[\"Texts\"])\n",
    "vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df_copy_1 = vector_df.copy()\n",
    "vector_df_copy_1[\"Texts\"] = vector_df_copy_1[\"Texts\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a scandal in bohemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the redheaded league</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a case of identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the boscombe valley mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the five orange pips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the man with the twisted lip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the adventure of the blue carbuncle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the adventure of the speckled band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the adventure of the engineers thumb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the adventure of the noble bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the adventure of the beryl coronet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the adventure of the copper beeches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Texts\n",
       "1                  a scandal in bohemia \n",
       "2                   the redheaded league\n",
       "3                    a case of identity \n",
       "4            the boscombe valley mystery\n",
       "5                   the five orange pips\n",
       "6           the man with the twisted lip\n",
       "7    the adventure of the blue carbuncle\n",
       "8     the adventure of the speckled band\n",
       "9   the adventure of the engineers thumb\n",
       "10   the adventure of the noble bachelor\n",
       "11    the adventure of the beryl coronet\n",
       "12   the adventure of the copper beeches"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df_copy_1[\"Texts\"] = vector_df_copy_1[\"Texts\"].str.replace(\"[^\\w\\s]\",\"\",regex=True)\n",
    "vector_df_copy_1[\"Texts\"] = vector_df_copy_1[\"Texts\"].str.replace(\"\\d\",\"\",regex=True)\n",
    "vector_df_copy_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_df_copy_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mvector_df_copy_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTexts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m vector_df_copy_1\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m vector_df_copy_1\n",
      "File \u001b[1;32mc:\\Users\\Umut\\.conda\\envs\\notebook\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umut\\.conda\\envs\\notebook\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umut\\.conda\\envs\\notebook\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Umut\\.conda\\envs\\notebook\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Umut\\.conda\\envs\\notebook\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_df_copy_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vector_df_copy_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m vector_df_copy_1\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m vector_df_copy_1\n",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_df_copy_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vector_df_copy_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(i \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43msw\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()))\n\u001b[0;32m      2\u001b[0m vector_df_copy_1\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m vector_df_copy_1\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sw' is not defined"
     ]
    }
   ],
   "source": [
    "vector_df_copy_1[\"Texts\"] = vector_df_copy_1[\"Texts\"].apply(lambda x: \" \".join(i if i not in sw else \"\"  for i in x.split()))\n",
    "vector_df_copy_1.reset_index(drop=True, inplace=True)\n",
    "vector_df_copy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coronet    1\n",
       "copper     1\n",
       "beeches    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete low frequency words\n",
    "\n",
    "#words = []\n",
    "#vector_df_copy_1[\"Texts\"].apply(lambda x: [words.append(i) for i in x.split()])\n",
    "#words = pd.Series(words)\n",
    "#words.value_counts()\n",
    "\n",
    "# Or\n",
    "delete = pd.Series(\" \".join(vector_df_copy_1[\"Texts\"]).split()).value_counts()[-3:]\n",
    "delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [scandal, bohemia]\n",
       "1               [redheaded, league]\n",
       "2                  [case, identity]\n",
       "3       [boscombe, valley, mystery]\n",
       "4              [five, orange, pips]\n",
       "5               [man, twisted, lip]\n",
       "6      [adventure, blue, carbuncle]\n",
       "7       [adventure, speckled, band]\n",
       "8     [adventure, engineers, thumb]\n",
       "9      [adventure, noble, bachelor]\n",
       "10      [adventure, beryl, coronet]\n",
       "11     [adventure, copper, beeches]\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "vector_df_copy_1[\"Texts\"].apply(lambda x: TextBlob(x).words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            scandal bohemia\n",
       "1              redhead leagu\n",
       "2                 case ident\n",
       "3     boscomb valley mysteri\n",
       "4             five orang pip\n",
       "5              man twist lip\n",
       "6     adventur blue carbuncl\n",
       "7       adventur speckl band\n",
       "8       adventur engin thumb\n",
       "9     adventur nobl bachelor\n",
       "10    adventur beryl coronet\n",
       "11     adventur copper beech\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming Köklerine ayırma\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "st = PorterStemmer()\n",
    "\n",
    "vector_df_copy_1[\"Texts\"].apply(lambda x: \" \".join(  st.stem(i)   for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Umut\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization \n",
    "import nltk\n",
    "from textblob  import Word\n",
    "#nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              scandal bohemia\n",
       "1             redheaded league\n",
       "2                case identity\n",
       "3      boscombe valley mystery\n",
       "4              five orange pip\n",
       "5              man twisted lip\n",
       "6     adventure blue carbuncle\n",
       "7      adventure speckled band\n",
       "8     adventure engineer thumb\n",
       "9     adventure noble bachelor\n",
       "10     adventure beryl coronet\n",
       "11      adventure copper beech\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df_copy_1[\"Texts\"] = vector_df_copy_1[\"Texts\"].apply(lambda x: \" \".join(  Word(i).lemmatize()   for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        A scandal in Bohemia 01,\n",
       "2         The Red-Headed League,2\n",
       "3          A Case, of Identity 33\n",
       "4    The Boscombe Valley Mystery4\n",
       "5           The Five Orange Pips1\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df[\"Texts\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            scandal  bohemia\n",
       "1            redheaded league\n",
       "2              case  identity\n",
       "3     boscombe valley mystery\n",
       "4            five orange pips\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df_copy_1[\"Texts\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess(text,low_freq_words):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^\\w\\s]\",\"\",text)\n",
    "    text = re.sub(\"\\d\",\"\",text)\n",
    "    \n",
    "    # Stopwords / Low Frequency Words\n",
    "    sw = stopwords.words(\"english\")\n",
    "    text = \" \".join(i if i not in sw else \"\"  for i in text.split())\n",
    "    text = \" \".join(i if i not in low_freq_words else \"\"  for i in text.split())    \n",
    "\n",
    "    # Lemmatization\n",
    "    # nltk.download(\"wordnet\")\n",
    "    text = \" \".join( Word(i).lemmatize() for i in text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Bu', 'örneğin']),\n",
       " WordList(['örneğin', 'anlaşılabilmesi']),\n",
       " WordList(['anlaşılabilmesi', 'için']),\n",
       " WordList(['için', 'daha']),\n",
       " WordList(['daha', 'fazla']),\n",
       " WordList(['fazla', 'örnek']),\n",
       " WordList(['örnek', 'cümleler']),\n",
       " WordList(['cümleler', 'yazmak']),\n",
       " WordList(['yazmak', 'gerekmektedir'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP Applications\n",
    "\n",
    "# 1. N-grams\n",
    "example_string = \"Bu örneğin anlaşılabilmesi için daha fazla örnek cümleler yazmak gerekmektedir.\"\n",
    "TextBlob(example_string).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bu', 'NNP'),\n",
       " ('örneğin', 'NNP'),\n",
       " ('anlaşılabilmesi', 'VBZ'),\n",
       " ('için', 'JJ'),\n",
       " ('daha', 'NN'),\n",
       " ('fazla', 'NN'),\n",
       " ('örnek', 'NNP'),\n",
       " ('cümleler', 'NN'),\n",
       " ('yazmak', 'NN'),\n",
       " ('gerekmektedir', 'NN')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Part of Speech Tagging (POS)\n",
    "#nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "TextBlob(example_string).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        [(scandal, NN), (bohemia, NN)]\n",
       "1                      [(redheaded, VBN), (league, NN)]\n",
       "2                          [(case, NN), (identity, NN)]\n",
       "3         [(boscombe, NN), (valley, NN), (mystery, NN)]\n",
       "4               [(five, CD), (orange, NN), (pips, NNS)]\n",
       "5                [(man, NN), (twisted, VBD), (lip, NN)]\n",
       "6        [(adventure, NN), (blue, JJ), (carbuncle, NN)]\n",
       "7        [(adventure, NN), (speckled, VBD), (band, NN)]\n",
       "8     [(adventure, NN), (engineers, NNS), (thumb, VBP)]\n",
       "9        [(adventure, NN), (noble, JJ), (bachelor, NN)]\n",
       "10        [(adventure, NN), (beryl, NN), (coronet, NN)]\n",
       "11      [(adventure, NN), (copper, NN), (beeches, NNS)]\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df_copy_1[\"Texts\"].apply(lambda x: TextBlob(x).tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Python', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('useful', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('tools', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('experienced', 'VBN'),\n",
       " ('data', 'NNS'),\n",
       " ('scientist', 'NN'),\n",
       " ('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('easy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('use', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('learn', 'VB'),\n",
       " ('R', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('programming', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('free', 'JJ'),\n",
       " ('software', 'NN'),\n",
       " ('environment', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('used', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('statistical', 'JJ'),\n",
       " ('computing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('graphics', 'NNS'),\n",
       " ('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('programming', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('lets', 'VBZ'),\n",
       " ('you', 'PRP'),\n",
       " ('work', 'VB'),\n",
       " ('quickly', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('integrate', 'VB'),\n",
       " ('systems', 'NNS'),\n",
       " ('more', 'RBR'),\n",
       " ('effectively', 'RB')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Chunking: Türkçe açıklama: Cümledeki kelimelerin bir araya gelerek oluşturduğu gruplar.\n",
    "\n",
    "example_string_en = \"\"\"R and Python are useful data science tools for the new or experienced data scientist.\n",
    "\n",
    "Python is a general-purpose programming language that is easy to use and learn.\n",
    "\n",
    "R is a programming language and free software environment that is used for statistical computing and graphics.\n",
    "\n",
    "Python is a programming language that lets you work quickly and integrate systems more effectively.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "pos = TextBlob(example_string_en).tags\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ec = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_ec)\n",
    "result = rp.parse(pos)\n",
    "#result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Named Entity Recognition (NER): nesnelerin tanımlanması\n",
    "example_string_en = \"\"\"The United States of America (USA) is commonly known as the United States (U.S. or US) or America.\"\"\"\n",
    "\n",
    "from nltk import ne_chunk, word_tokenize, pos_tag\n",
    "\n",
    "#nltk.download(\"maxent_ne_chunker\")\n",
    "#nltk.download('maxent_ne_chunker_tab')\n",
    "#nltk.download(\"words\")\n",
    "\n",
    "#ne_chunk(pos_tag(word_tokenize(example_string_en))).draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Char_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scandal  bohemia</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>redheaded league</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case  identity</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boscombe valley mystery</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five orange pips</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man   twisted lip</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adventure   blue carbuncle</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adventure   speckled band</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adventure   engineers thumb</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adventure   noble bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adventure   beryl coronet</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adventure   copper beeches</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Texts  Word_Count  Char_Count\n",
       "0               scandal  bohemia           2          17\n",
       "1               redheaded league           2          17\n",
       "2                 case  identity           2          15\n",
       "3        boscombe valley mystery           3          24\n",
       "4               five orange pips           3          17\n",
       "5              man   twisted lip           3          18\n",
       "6     adventure   blue carbuncle           3          27\n",
       "7      adventure   speckled band           3          26\n",
       "8    adventure   engineers thumb           3          28\n",
       "9     adventure   noble bachelor           3          27\n",
       "10     adventure   beryl coronet           3          26\n",
       "11    adventure   copper beeches           3          27"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Feature Extraction\n",
    "# 1. Char/Word Count\n",
    "vector_df_copy_1[\"Char_Count\"] = vector_df_copy_1[\"Texts\"].str.len()\n",
    "vector_df_copy_1[\"Word_Count\"] = vector_df_copy_1[\"Texts\"].apply(lambda x: len(x.split()))\n",
    "vector_df_copy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text visualization\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>hearst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortle</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       series escapade demonstrating adage good goose...          1  \n",
       "1          series escapade demonstrating adage good goose          2  \n",
       "2                                                  series          2  \n",
       "3                                                                  2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                             hearst          2  \n",
       "156056                           forced avuncular chortle          1  \n",
       "156057                                  avuncular chortle          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                            chortle          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing\n",
    "\n",
    "low_freq = pd.Series(\" \".join(df[\"Phrase\"]).split()).value_counts()[-1000:]\n",
    "df[\"Phrase\"] = df[\"Phrase\"].apply(lambda x: preprocess(x,low_freq))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Analysis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf1 = df[\"Phrase\"].apply(lambda x: pd.Series(x).value_counts())\n",
    "#tf1 = (df[\"Phrase\"]).apply(lambda x: pd.Series(x).value_counts()).sum().reset_index()\n",
    "#tf1.columns = [\"words\",\"tf\"]\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf1\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf1' is not defined"
     ]
    }
   ],
   "source": [
    "tf1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
